# Prepare-Data-Exploration
## Preparing the Data Correctly 
+ Understanding the different type of data and data structures
+ What type of data is right for the question you are trying to answer
+ Practical skills about how to extract, use, organize, and protect your data
## Data Analysis Process Steps
+ Ask
+ Prepare
+ Process
+ Analyze
+ Share
+ Act
<details>
 <summary>
Collecting Data
 </summary>
<blockquote>
 
+ every thing is data
+ in every day each second we are getting data 
+ every picture is a data ..... a img has data in its pixels
+ but we do have to maintain the privacy constraint.
+ Another way is doing survey
+ Interview is also a way of collecting data
+ Scientist also generate data by studying behavior by the help of microscope and stuff
+ Data generated online is directly generated

<hr>

### Here are few ways we can collect data
+ Interviews
+ Observation
+ Forms
+ Questionaries
+ Surveys
+ Cookies
<details>
 <summary>What to collect for your data</summary>  
 
Here are few factors we have to consider while considering what should we collect:  
+ How the data will be collected
+ Choose data sources : Collecting first-party data is typically perferred method because you know exactly where it came from
+ Decide what data to use
+ How much data to collect
+ Select the right datatype
 <details><summary>How the data will be collected</summary>
Decide if you will collect the data using your own resources or receive (and possibly purchase it) from another party. Data that you collect yourself is called first-party data.  
 </details>  
 
## Data sources  
If you don’t collect the data using your own resources, you might get data from second-party or third-party data providers. Second-party data is collected directly by another group and then sold. Third-party data is sold by a provider that didn’t collect the data themselves. Third-party data might come from a number of different sources.  
### First-party data
``
Data collected by an individual or group by using their own reference.
``
### Second-party data
`` 
Data collected by a group directly from its audience and then sold. In our example, if you aren't able to collect your own data, you might buy it from an organization that's led traffic pattern studies in your city.
 ``
 ### Third-party Data
 ``
 Data collected from outside sources who did not collect it directly. This data might have come from a number of different sources before you investigated it. It might not be as reliable, but that doesn't mean it can't be useful. You'll just want to make sure you check it for accuracy, bias, and credibility.
 ``
 ### Note
 ``
 no matter what kind of data you use, it needs to be inspected for accuracy and trustworthiness.
 ``  
   
Just remember that the data you choose should apply to your needs, and it must be approved for use. As a data analyst, it's your job to decide what data to use, and that means choosing the data that can help you find answers and solve problems and not getting distracted by other data. In traffic example, financial data probably wouldn't be that helpful, but existing data about high volume traffic times would be.
## Solving your business problem  
Datasets can show a lot of interesting information. But be sure to choose data that can actually help solve your problem question. For example, if you are analyzing trends over time, make sure you use time series data — in other words, data that includes dates.  
## How much data Needs to be collect:   
If you are collecting your own data, make reasonable decisions about sample size. A random sample from existing data might be fine for some projects. Other projects might need more strategic data collection to focus on certain criteria. Each project has its own needs.   
In data analytics,`` a population refers to all possible data values in a certain data set.`` If you're analyzing data about car traffic in a city, your population would be all the cars in that area. But collecting data from the entire population can be pretty challenging. That's why a sample can be useful.`` A sample is a part of a population that is representative of the population.`` You might collect a data sample about one spot in the city and analyze the traffic there, or you might pull a random sample from all existing data in the population.  
## Select the right data:
make sure you select the right data type. For traffic data, an appropriate data type could be the dates of traffic records stored in a date format. The dates could help you figure what days of the week there is likely to be a high volume of traffic in the future.

<hr>  
  
### Time frame
If you are collecting your own data, decide how long you will need to collect it, especially if you are tracking trends over a long period of time. If you need an immediate answer, you might not have time to collect new data. In this case, you would need to use historical data that already exists.    
Use the flowchart below if data collection relies heavily on how much time you have:    
  
![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/4fe6aeb9-f123-46e1-9695-d85ea790c7a3)

## Question

![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/54474c16-c37f-4cc4-8060-d30cec87079d)

![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/41a12688-1903-4971-9c9f-5853694afa1c)
 </details>
</blockquote> 
</details>
<details>
 <summary>Data Format</summary>
 
 ## Primary Vs Secondary
 | Data Formation  | Definition |
| ------------- | ------------- |
| Primary Data | Collected by a researcher from first-hand sources  |
| Secondary Data  | Gathered by other people or from other research  |
 
 ## Internal Vs External
| Data Formation  | Definition |
| ------------- | ------------- |
| Internal Data | Data that lives inside a company’s own systems  |
| External Data  | Data that lives outside of a company or organization  |
 

 ## Continuous Vs Discrete
| Data Formation  | Definition |
| ------------- | ------------- |
| Continuous Data | Data that is measured and can have almost any numeric value  |
| Discrete Data  | Data that is counted and has a limited number of values  |
 

 ## Qualitative Vs Quantitative
| Data Formation  | Definition |
| ------------- | ------------- |
| Qualitative Data | Subjective and explanatory measures of qualities and characteristics  |
| Quantitative Data  | Specific and objective measures of numerical facts  |
 

 ## Nomnial Vs Ordinal
| Data Formation  | Definition |
| ------------- | ------------- |
| Nomnial Data | A type of qualitative data that isn’t categorized with a set order  |
| Ordinal Data  |  A type of qualitative data with a set order or scale  | 
 
 ## Structured Vs UnStructured
| Data Formation  | Definition |
| ------------- | ------------- |
| Structure Data | Data organized in a certain format, like rows and columns  |
| UnStructure Data  |  Data that isn’t organized in any easily identifiable manner  | 
 
</details>

<details>
 <summary>The structure of data</summary>
   
 Data is everywhere and it can be stored in lots of ways. Two general categories of data are: 
  
- **Structured data:** Organized in a certain format, such as rows and columns.

- **Unstructured data:** Not organized in any easy-to-identify way.
  
For example, when you rate your favorite restaurant online, you're creating structured data. But when you use Google Earth to check out a satellite image of a restaurant location, you're using unstructured data. 
  
Here's a refresher on the characteristics of structured and unstructured data:  
   
 ![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/60e7ea0b-0756-41b2-b4c8-ead2a4b63613)  
   
## Structured data  
As we described earlier, structured data is organized in a certain format. This makes it easier to store and query for business needs. If the data is exported, the structure goes along with the data.

## Unstructured data  
Unstructured data can’t be organized in any easily identifiable manner. And there is much more unstructured than structured data in the world. Video and audio files, text files, social media content, satellite imagery, presentations, PDF files, open-ended survey responses, and websites all qualify as types of unstructured data. 

## The fairness issue  
The lack of structure makes unstructured data difficult to search, manage, and analyze. But recent advancements in artificial intelligence and machine learning algorithms are beginning to change that. Now, the new challenge facing data scientists is making sure these tools are inclusive and unbiased. Otherwise, certain elements of a dataset will be more heavily weighted and/or represented than others. And as you're learning, an unfair dataset does not accurately represent the population, causing skewed outcomes, low accuracy levels, and unreliable analysis.

</details>
<details>
 <summary>Data modeling levels and techniques</summary>
     
Data models help keep data consistent and enable people to map out how data is organized. A basic understanding makes it easier for analysts and other stakeholders to make sense of their data and use it in the right ways. 
  
**Important note:** As a junior data analyst, you won't be asked to design a data model. But you might come across existing data models your organization already has in place. 
   
## What is data modeling?
  
Data modeling is the process of creating diagrams that visually represent how data is organized and structured.  These visual representations are called data models. You can think of data modeling as a blueprint of a house. At any point, there might be electricians, carpenters, and plumbers using that blueprint. Each one of these builders has a different relationship to the blueprint, but they all need it to understand the overall structure of the house. Data models are similar; different users might have different data needs, but the data model gives them an understanding of the structure as a whole. 
 
## Levels of data modeling
Each level of data modeling has a different level of detail.  
  
 ![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/77076d67-6210-4c1d-9040-51d41f303adf)
  
- Conceptual data modeling gives a high-level view of the data structure, such as how data interacts across an organization. For example, a conceptual data model may be used to define the business requirements for a new database. A conceptual data model doesn't contain technical details. 

- Logical data modeling focuses on the technical details of a database such as relationships, attributes, and entities. For example, a logical data model defines how individual records are uniquely identified in a database. But it doesn't spell out actual names of database tables. That's the job of a physical data model.

- Physical data modeling depicts how a database operates. A physical data model defines all entities and attributes used; for example, it includes table names, column names, and data types for the database.


## Data-modeling techniques
There are a lot of approaches when it comes to developing data models, but two common methods are the Entity Relationship Diagram (ERD) and the Unified Modeling Language (UML) diagram. ERDs are a visual way to understand the relationship between entities in the data model. UML diagrams are very detailed diagrams that describe the structure of a system by showing the system's entities, attributes, operations, and their relationships. As a junior data analyst, you will need to understand that there are different data modeling techniques, but in practice, you will probably be using your organization’s existing technique.   
  

## Data analysis and data modeling
Data modeling can help you explore the high-level details of your data and how it is related across the organization’s information systems. Data modeling sometimes requires data analysis to understand how the data is put together; that way, you know how to map the data. And finally, data models make it easier for everyone in your organization to understand and collaborate with you on your data. This is important for you and everyone on your team!   
 
</details>
<details>
 <summary>Understanding Boolean data</summary>
   
These conditions are created with Boolean operators, including AND, OR, and NOT. These operators are similar to mathematical operators and can be used to create logical statements that filter your results. Data analysts use Boolean statements to do a wide range of data analysis tasks, such as creating queries for searches and checking for conditions when writing programming code. 
   
## Boolean logic example
Imagine you are shopping for shoes, and are considering certain preferences:

- You will buy the shoes only if they are pink and grey

- You will buy the shoes if they are entirely pink or entirely grey, or if they are pink and grey

- You will buy the shoes if they are grey, but not if they have any pink

Below are Venn diagrams that illustrate these preferences. AND is the center of the Venn diagram, where two conditions overlap. OR includes either condition. NOT includes only the part of the Venn diagram that doesn't contain the exception.  
  
![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/a80b8bce-4fe3-4886-9689-6a664be4af49)
   
### The AND operator
Your condition is “If the color of the shoe has any combination of grey and pink, you will buy them.” The Boolean statement would break down the logic of that statement to filter your results by both colors. It would say “IF (Color=”Grey”) AND (Color=”Pink”) then buy them.” The AND operator lets you stack multiple conditions. 

Below is a simple truth table that outlines the Boolean logic at work in this statement. In the Color is Grey column, there are two pairs of shoes that meet the color condition. And in the Color is Pink column, there are two pairs that meet that condition. But in the If Grey AND Pink column, there is only one pair of shoes that meets both conditions. So, according to the Boolean logic of the statement, there is only one pair marked true. In other words, there is one pair of shoes that you can buy.
  
 ![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/3cf442ad-8325-4e25-af1c-b2760c5ddc19)
  
### The OR operator  
   
The OR operator lets you move forward if either one of your two conditions is met. Your condition is “If the shoes are grey or pink, you will buy them.” The Boolean statement would be “IF (Color=”Grey”) OR (Color=”Pink”) then buy them.” Notice that any shoe that meets either the Color is Grey or the Color is Pink condition is marked as true by the Boolean logic. According to the truth table below, there are three pairs of shoes that you can buy.  
   
 ![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/d4b6a81b-6aa5-4689-902b-4fa40eff052b)  
   
### The NOT operator  
   
Finally, the NOT operator lets you filter by subtracting specific conditions from the results. Your condition is "You will buy any grey shoe except for those with any traces of pink in them." Your Boolean statement would be “IF (Color="Grey") AND (Color=NOT “Pink”) then buy them.” Now, all of the grey shoes that aren't pink are marked true by the Boolean logic for the NOT Pink condition. The pink shoes are marked false by the Boolean logic for the NOT Pink condition. Only one pair of shoes is excluded in the truth table below.
  
 ![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/57cac2d5-ce18-4caf-9c4d-2ba573e4abba)  
   
## The power of multiple conditions
For data analysts, the real power of Boolean logic comes from being able to combine multiple conditions in a single statement. For example, if you wanted to filter for shoes that were grey or pink, and waterproof, you could construct a Boolean statement such as: “IF ((Color = “Grey”) OR (Color = “Pink”)) AND (Waterproof=“True”).”  Notice that you can use parentheses to group your conditions together. 

Whether you are doing a search for new shoes or applying this logic to your database queries, Boolean logic lets you create multiple conditions to filter your results. And now that you know a little more about how Boolean logic is used, you can start using it!



</details>
<details>
 <summary>Transforming Data</summary>
   
 ### What is data transformation?  
   

Data transformation is the process of changing the data’s format, structure, or values. As a data analyst, there is a good chance you will need to transform data at some point to make it easier for you to analyze it. 

- Data transformation usually involves:

- Adding, copying, or replicating data 

- Deleting fields or records 

- Standardizing the names of variables

- Renaming, moving, or combining columns in a database

- Joining one set of data with another

- Saving a file in a different format. For example, saving a spreadsheet as a comma separated values (CSV) file.  
   
### Why transform data?
Goals for data transformation might be: 

- Data organization: better organized data is easier to use

- Data compatibility: different applications or systems can then use the same data

- Data migration: data with matching formats can be moved from one system to another

- Data merging: data with the same organization can be merged together

- Data enhancement: data can be displayed with more detailed fields 

- Data comparison: apples-to-apples comparisons of the data can then be made   
   
### Data transformation example: data merging  
   
Mario is a plumber who owns a plumbing company. After years in the business, he buys another plumbing company. Mario wants to merge the customer information from his newly acquired company with his own, but the other company uses a different database. So, Mario needs to make the data compatible. To do this, he has to transform the format of the acquired company’s data. Then, he must remove duplicate rows for customers they had in common. When the data is compatible and together, Mario’s plumbing company will have a complete and merged customer database.
   
### Data transformation example: data organization (long to wide)  
   
To make it easier to create charts, you may also need to transform long data to wide data. Consider the following example of transforming stock prices (collected as long data) to wide data. 
  
Long data is data where each row contains a single data point for a particular item. In the long data example below, individual stock prices (data points) have been collected for Apple (AAPL), Amazon (AMZN), and Google (GOOGL) (particular items) on the given dates.

Long data example: Stock prices  

![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/5ac5936a-b1aa-4f3f-806a-64a5ddad636c)

 
 Wide data is data where each row contains multiple data points for the particular items identified in the columns. 

Wide data example: Stock prices  
   
![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/14f3f323-6972-4c16-a495-53ae2ef57257)
      
With data transformed to wide data, you can create a chart comparing how each company's stock changed over the same period of time.  

You might notice that all the data included in the long format is also in the wide format. But wide data is easier to read and understand. That is why data analysts typically transform long data to wide data more often than they transform wide data to long data. The following table summarizes when each format is preferred:  
   
![image](https://github.com/AyeshaIrshad1337/Prepare-Data-Exploration/assets/104616632/3e1479c5-5612-4044-9fed-1e700b35c32f)
 
</details>
